# 物体检测网络总结
## 引言
首先，借助CS231N李飞飞的课中的一张图表明物体检测相对于图像分类的难度。在目标检测问题中，给定一个图像，找到它所包含的物体，找到它们的位置并对它们进行分类。目标检测模型通常是在一组特定的类集合上进行训练的，所以模型只会定位和分类图像中的那些类。另外，对象的位置通常采用矩形边界框表示。相对于图像分类，图像检测通常涉及多个类别，同时还要识别出物体的位置。

![image](https://user-images.githubusercontent.com/30947306/62823166-d600c380-bbc0-11e9-941c-3263dd820d71.png)

## 评估指标
在分类中，精确度和召回率是一个简单直观的统计评估指标，但是在目标检测中即使物体检测器在图像中检测到物体，如果无法找到它所在的图像中的哪个位置也是无用的。由于需要同时预测图像中的目标的发生和位置，所以在计算精确度和召回率的评估上与普通的分类有所不同。
在物体检测中，通常采用MAP(Mean Average Precision) 作为评价指标。在具体讨论MAP之前首先需要引入IoU（Intersection Over Unit）用来评价边界框的准确性。IoU是预测框与ground truth的交集和并集的比值，也被称为Jaccard指数。如下图所示IoU的观点非常简明，如其字面意思，通过ground truth和prediction的预测框的交集和并集的几何面积比，当完全吻合时上述比例为1，否则<=1。

![image](https://user-images.githubusercontent.com/30947306/62823175-e9139380-bbc0-11e9-8ab2-8c7250f8e309.png)

更进一步的计算precision和recall，需要获得TP，FP，TN，FN。通过之前计算的IoU判定TP or FP，通常采用某一阈值，在PASCAL VOC采用0.5作为阈值。当IoU>0.5，认为TP，否则NP。另一方面在TP的计算上存在困难，故通常通过计算FN来解决，即漏检的数量。
另一方面上，置信度影响P/N的判定，阈值以上的置信度判定为Positive，以下的判定为Negative。
基于上述两点，对于一张图片，计算每个Positive预测框与ground truth的IoU值，并取最大的IoU值，认为该预测框检测到了那个IoU最大的ground truth。然后根据IoU阈值，我们可以计算出一张图片中各个类别的正确检测值（True Positives, TP）数量以及错误检测值数量（False Positives, FP）。从而每个类别的Precision=TP/(TP+FP)，同样的可以获得Recall=TP/(TP+FN)。
尽管已经获得了Precision和Recall，但是上述两个量受到IoU和置信度阈值的影响，IoU作为一个几何度量相对容易，比如在PASCAL VOC中采用0.5，但是置信度阈值方面却差异性甚大。因此提出了(Average Precision)AP的评价指标。具体的采用如下做法：
首先要对模型预测结果进行排序（按照各个预测值置信度降序排列）。那么给定一个rank，Recall和Precision仅在高于该rank值的预测结果中计算，改变rank值会改变recall值。VOC 2007选择11个不同的recall（[0, 0.1, ..., 0.9, 1.0]），可以认为是选择了11个rank，由于按照置信度排序，所以实际上等于选择了11个不同的置信度阈值。那么，AP就定义为在这11个recall下precision的平均值，其可以表征整个precision-recall曲线（曲线下面积）。上述标准在2010年后做了调整不再使用11个点而是使用所有数据。
## 主流的物体检测网络
主要包括三种网络结构：1）使用Proposal，Faster R-CNN；2) SSD；3）YOLO。
3.1 Faster R-CNN<br>
R-CNN，Fast R-CNN和Faster R-CNN一脉相承。R-CNN核心思想是在对每张图片选取多个区域，然后每个区域作为一个样本进入一个卷积神经网络来抽取特征，最后使用分类器来对齐分类，和一个回归器来得到准确的边框。缺点是上千候选区，预测慢。Fast R-CNN中使用选择性搜索选取的区域是作用在卷积神经网络提取的特征上，只需要对原始的输入图片做一次特征提取即可，节省了大量重复计算。但是Fast R-CNN仍沿用了R-CNN的选择性搜索方法来选择区域。这个通常很慢。Faster R-CNN做的主要改进是提出了区域提议网络（RPN）来替代选择性搜索。RPN思想非常直观，预先配置好的一些区域，然后通过神经网络来判断这些区域是不是感兴趣的，如果是，那么再预测一个更加准确的边框，有效降低搜索任何形状的边框的代价。
3.2 SSD<br>
R-CNN系列模型里，区域提议和分类是分作两块来进行的。SSD将其统一成一个步骤来使得模型更加简单并且速度更快，SSD里直接使用一个num_class+1类分类器来判断它对应的是哪类物体，还是背景，同时不再有额外的回归器对边框再进一步预测，而是直接使用单个回归器来预测真实边框。另一方面，SSD不只是对卷积神经网络输出的特征做预测，还会进一步将特征通过卷积和池化层变小来做预测，达到多尺度预测的效果。
3.3 YOLO<br>
Faster R-CNN和SSD，生成的锚框仍然有大量相互重叠，导致大量的区域被重复计算，YOLO力图解决这个问题，将图片特征均匀的切成 S × S 块，每一块当做一个锚框。每个锚框预测B 个边框，以及这个锚框主要包含哪个物体。
## 模型之间的对比
精度上：RFCN的准确度是最高的。

![image](https://user-images.githubusercontent.com/30947306/62823191-16f8d800-bbc1-11e9-8b11-733172d05725.png)

速度上：单步方法SSD，YOLO最快。

![image](https://user-images.githubusercontent.com/30947306/62823193-195b3200-bbc1-11e9-8786-4d270f0465bd.png)
 
mAP上：RetinaNet占优

![image](https://user-images.githubusercontent.com/30947306/62823194-1d874f80-bbc1-11e9-9a99-11dbe04d8483.png)

物体大小：对于大物体，SSD即使使用一个较弱的特征抽取器也可以获取较好的精确度。但在小物体上SSD的表现结果非常不好。

![image](https://user-images.githubusercontent.com/30947306/62823195-211ad680-bbc1-11e9-9757-c8f7f3a5ec54.png)
 
